# ğŸ¦™ ExplainLLama Web App

Welcome to **ExplainLLama**, an AI-powered web application designed for Java bug fixing and explanation generation. This tool utilizes a **dual decoder transformer model** trained to analyze Java code bugs and generate detailed explanations for debugging assistance. The project provides both a backend API and a user-friendly frontend interface for seamless interactions.

ğŸ§‘â€ğŸ“ **This project is developed as part of our Final Year Research Project.** ğŸ“

<img src="https://filedn.eu/lVNP1DcGQUE5OPMMHbPaQeb/ExplainLlama_Web_App/ExplainLLama_Web_UI.png" width="700">

---

## ğŸŒŸ Features
âœ… **Java Bug Fixing Assistance** - Identify and fix Java code errors efficiently.  
âœ… **AI-Powered Explanation Generation** - Get detailed insights into why a bug occurs.  
âœ… **Web-Based Interface** - Easy-to-use UI for debugging and explanations.  
âœ… **Robust Backend API** - Efficient request handling and model interaction.  
âœ… **Secure & Scalable** - Built with best practices for security and performance.

---

## ğŸ“¦ Installation

### ğŸ“Œ Prerequisites
Ensure you have the following installed before proceeding:
- ğŸ **Python** (>=3.8)
- ğŸ“¦ **pip** (for managing dependencies)
- ğŸ”¹ **Virtual environment** (optional but recommended)
- ğŸ–¥ **Node.js** and **npm** (for frontend setup)

### ğŸ”§ Setup
1. **Clone the Repository**
   ```sh
   git clone https://github.com/your-repo/ExplainLLama_Web_App.git
   cd ExplainLLama_Web_App
   ```

2. **Create a Virtual Environment (Recommended)**
   ```sh
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   ```

3. **Install Backend Dependencies**
   ```sh
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Running the Application

### âš™ï¸ Backend Setup
1. **Navigate to the Backend Directory**
   ```sh
   cd backend
   ```
2. **Apply Migrations** (Ensuring the database is up-to-date)
   ```sh
   python manage.py migrate
   ```
3. **Start the Development Server**
   ```sh
   python manage.py runserver
   ```

### ğŸ¨ Frontend Setup
1. **Navigate to the Frontend Directory**
   ```sh
   cd frontend
   ```
2. **Install Dependencies**
   ```sh
   npm install
   ```
3. **Start the Frontend Server**
   ```sh
   npm start
   ```

This will start the frontend development server, and you can access the application at `http://localhost:3000`.

---

## ğŸ”‘ Environment Variables
Copy `.env_sample` to `.env` and update necessary configurations:
```sh
cp .env_sample .env
```

---

## ğŸ¤ Contributing
We welcome contributions! ğŸ‰ If you'd like to improve ExplainLLama, follow these steps:
1. Fork the repository ğŸ´
2. Create a new branch ğŸŒ¿
3. Make your changes âœï¸
4. Submit a pull request ğŸ“©


## ğŸ‘¥ Team Members
- ğŸ§‘â€ğŸ’» **Suwan Sankaja** - [GitHub Profile](https://github.com/SuwanSankaja)  
- ğŸ§‘â€ğŸ’» **Gimhan Sandeeptha** - [GitHub Profile](https://github.com/gimhansandeeptha)  
- ğŸ§‘â€ğŸ’» **Ruwan Ranasinghe** - [GitHub Profile](https://github.com/RuwanUdayanga)  

ğŸš€ **GitHub Organization:** [ExplainaCode Organization](https://github.com/ExplainaCode)

---

## ğŸ“§ Contact
ğŸ“© **For issues or inquiries, reach out at:** dev@suwansankaja.com`  
ğŸ™ **GitHub Issues:** [Open an issue](https://github.com/SuwanSankaja/ExplainLLama_Web_App/issues)

ğŸ’¡ _Thank you for using ExplainLLama! Happy coding!_ ğŸ‰

